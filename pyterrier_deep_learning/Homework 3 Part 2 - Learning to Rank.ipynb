{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Oe730o8rzyn"
   },
   "source": [
    "# SI 650 / EECS 549: Homework 3 Part 2\n",
    "\n",
    "Homework 3 Part 2 will have you working with Learning to Rank approaches, which as we've seen are highly competitive when enough data is available. Part 2 should be completed after Part 1 and will use some small parts of that code to construct an index and load data.\n",
    "\n",
    "If you haven't worked with them before, Part 2 will expose you to [overloaded python operators](https://www.geeksforgeeks.org/operator-overloading-in-python/), which will let you call functions using alternative python syntax. For example, if you're using two Python `list` objects, you can interact with them using `+` to call the equivalent method. \n",
    "\n",
    "In Part 2, you'll work on the following tasks:\n",
    " - Construct and learn learning-to-rank pipelines\n",
    " - Add new features for learning-to-rank\n",
    " - Evaluate learning-to-rank models\n",
    " \n",
    "Part 2 can be run on most laptops as well. Some of the machine learning models may take a few minutes to train but you are also welcome to run these on Great Lakes. None of the code in this part involves deep learning or requires a GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0edvI3LDtOym"
   },
   "source": [
    "### Launch PyTerrier\n",
    "Import the packages you need and launch PyTerrier like we did in Part 1. You will still need to make sure `JAVA_HOME` is set for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34696,
     "status": "ok",
     "timestamp": 1616668024544,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "mkCdrWdRzS64",
    "outputId": "c6770726-25a2-4971-b1e6-6fb44efb4f83"
   },
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37396,
     "status": "ok",
     "timestamp": 1616668027562,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "SWc4UQgX6vDD",
    "outputId": "30cd0f3d-aafe-428f-eaa4-9163de61d4af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.7.1 has loaded Terrier 5.6 (built by craigmacdonald on 2021-09-17 13:27)\n"
     ]
    }
   ],
   "source": [
    "if not pt.started():\n",
    "    pt.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p18d1tpJvD_5"
   },
   "source": [
    "# Indexing CORD19\n",
    "\n",
    "Like in Part 1, we'll again use the CORD19 data. However, **in Part 2, we will add in positional indexing.** This code will still look very similar to your code from Part 1. When creating the index, add the `blocks=True` argument, which will include word order information in the index. On most laptops, this process will take ~1 minute.\n",
    "\n",
    "You may see an error `java.io.IOException: Key 8lqzfj2e is not unique: 37597,11755` during indexing but you can safely ignore the error for the purposes of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 239,
     "referenced_widgets": [
      "562458b5bd6d4bb3a629932a2edc54d7",
      "224e088c2ac64cc29b1d78a5e850ebe4",
      "3cc8a8231dc44c768dffbc755dd0f2fb",
      "d998ea1d78fa458d94e3107bc2a514b5",
      "ae5b4e71f7a74bb8aaa7c8bf1e985993",
      "587cc3f3700b4201b750e8fd3408e34d",
      "c6b946af922e4b248a5bfecd99e11a8c",
      "eb34c2ee16c241ea955bb088632f603d"
     ]
    },
    "executionInfo": {
     "elapsed": 135816,
     "status": "ok",
     "timestamp": 1616668163381,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "C9E6oLubIeI4",
    "outputId": "0170a2d2-169e-4377-c538-a335efd8dec8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cord19 = pt.datasets.get_dataset('irds:cord19/trec-covid')\n",
    "pt_index_path = './terrier_trec_covid_positional_indices'\n",
    "\n",
    "if not os.path.exists(pt_index_path + \"/data.properties\"):\n",
    "    # create the index, using the IterDictIndexer indexer \n",
    "    iter_indexer = pt.IterDictIndexer(pt_index_path, overwrite=True, blocks=True)\n",
    "\n",
    "    # we give the dataset get_corpus_iter() directly to the indexer\n",
    "    # while specifying the fields to index and the metadata to record\n",
    "    index_ref = iter_indexer.index(cord19.get_corpus_iter(), fields=('abstract',), meta=['docno', 'text'], meta_lengths=[20, 4096])\n",
    "\n",
    "else:\n",
    "    # if you already have the index, create an IndexRef from the data in pt_index_path\n",
    "    # that we can use to load using the IndexFactory\n",
    "    index_ref = pt.IndexRef.of(pt_index_path)\n",
    "\n",
    "index = pt.IndexFactory.of(index_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OiM8I_fkUcQ9"
   },
   "source": [
    "## Transformers and Operators\n",
    "\n",
    "PyTerrier works extensively with objects/functions that _transform_ one input to another. We saw this behavior with the `BatchRetrieve` object that we used earlier to get search results, which had a `transform()` method that takes as input a dataframe, and returns another dataframe. We can think of this function as a *transformation* of the earlier dataframe (e.g., transforming the queries into results). PyTerrier has many such functions that act as  [transformers](https://pyterrier.readthedocs.io/en/latest/transformer.html). \n",
    "\n",
    "Let's use the transformer, `BatchRetrieve`, and this time specify that we'll use the TF-IDF word model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 554,
     "status": "ok",
     "timestamp": 1616668164873,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "UqMt-9UlTqLa",
    "outputId": "96e17d34-c984-418d-b087-24302b758e15"
   },
   "outputs": [],
   "source": [
    "tfidf = pt.BatchRetrieve(index, wmodel=\"TF_IDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GW3afDgPukvU"
   },
   "source": [
    "In PyTerrier, all transformers have been coded so that they be combined using Python operators, which is an example  of operator overloading. If we want to have the output of one transformer used as the input of another transformer, we can use the `>>` operator. This operator lets us compose a series of transformations to output our document rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "executionInfo": {
     "elapsed": 1823,
     "status": "ok",
     "timestamp": 1616668219672,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "e9HkXxtgug15",
    "outputId": "6bdd961d-4ff2-4b17-ffb6-6bbc6a42670a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [starting] https://ir.nist.gov/covidSubmit/data/topics-rnd5.xml\n",
      "[INFO] [finished] https://ir.nist.gov/covidSubmit/data/topics-rnd5.xml: [00:00] [18.7kB] [19.5MB/s]\n",
      "                                                                                 \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>146967</td>\n",
       "      <td>jkrj0lbm</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25564</td>\n",
       "      <td>jlzncyax</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>45549</td>\n",
       "      <td>8l411r1w</td>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>29359</td>\n",
       "      <td>gnxbfcod</td>\n",
       "      <td>3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>63537</td>\n",
       "      <td>cpc6v40g</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1</td>\n",
       "      <td>58583</td>\n",
       "      <td>wfcyaumm</td>\n",
       "      <td>995</td>\n",
       "      <td>4.0</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "      <td>59153</td>\n",
       "      <td>86vu0kjm</td>\n",
       "      <td>996</td>\n",
       "      <td>4.0</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1</td>\n",
       "      <td>59343</td>\n",
       "      <td>9n733bet</td>\n",
       "      <td>997</td>\n",
       "      <td>4.0</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1</td>\n",
       "      <td>59478</td>\n",
       "      <td>mx58ai55</td>\n",
       "      <td>998</td>\n",
       "      <td>4.0</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1</td>\n",
       "      <td>59875</td>\n",
       "      <td>d0x23frk</td>\n",
       "      <td>999</td>\n",
       "      <td>4.0</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    qid   docid     docno  rank  score               query\n",
       "0     1  146967  jkrj0lbm     0   25.0  coronavirus origin\n",
       "1     1   25564  jlzncyax     1   18.0  coronavirus origin\n",
       "2     1   45549  8l411r1w     2   15.0  coronavirus origin\n",
       "3     1   29359  gnxbfcod     3   14.0  coronavirus origin\n",
       "4     1   63537  cpc6v40g     4   14.0  coronavirus origin\n",
       "..   ..     ...       ...   ...    ...                 ...\n",
       "995   1   58583  wfcyaumm   995    4.0  coronavirus origin\n",
       "996   1   59153  86vu0kjm   996    4.0  coronavirus origin\n",
       "997   1   59343  9n733bet   997    4.0  coronavirus origin\n",
       "998   1   59478  mx58ai55   998    4.0  coronavirus origin\n",
       "999   1   59875  d0x23frk   999    4.0  coronavirus origin\n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is our first retrieval transformer, which transforms a queries dataframe to a results dataframe\n",
    "tf = pt.BatchRetrieve(index, wmodel=\"Tf\")\n",
    "\n",
    "tf(cord19.get_topics(variant='title').head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our first pipeline using the `>>` operator. If we have two transformers, `a` and `b`, the result of `a >> b` is itself a transformer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "executionInfo": {
     "elapsed": 878,
     "status": "ok",
     "timestamp": 1616668229117,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "uHHIn-rMvk_5",
    "outputId": "2060c226-bbea-46db-e0a8-57f0086fc3d6"
   },
   "outputs": [],
   "source": [
    "pipeline = tf >> tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this pipeline like any other transformer. Here, we'll  pass in the very first query using `head(1)` and get the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Note: NumExpr detected 36 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "[INFO] NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>175892</td>\n",
       "      <td>zy8qjaai</td>\n",
       "      <td>0</td>\n",
       "      <td>7.080599</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>82224</td>\n",
       "      <td>8ccl9aui</td>\n",
       "      <td>1</td>\n",
       "      <td>6.775667</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>135326</td>\n",
       "      <td>ne5r4d4b</td>\n",
       "      <td>2</td>\n",
       "      <td>6.683114</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>93245</td>\n",
       "      <td>hmvo5b0q</td>\n",
       "      <td>3</td>\n",
       "      <td>6.507303</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>84953</td>\n",
       "      <td>ax6v6ham</td>\n",
       "      <td>4</td>\n",
       "      <td>6.483723</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1</td>\n",
       "      <td>136214</td>\n",
       "      <td>ygnxmcl1</td>\n",
       "      <td>995</td>\n",
       "      <td>1.640752</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "      <td>91270</td>\n",
       "      <td>853ipgea</td>\n",
       "      <td>996</td>\n",
       "      <td>1.634118</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1</td>\n",
       "      <td>146556</td>\n",
       "      <td>oshov14d</td>\n",
       "      <td>997</td>\n",
       "      <td>1.634118</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1</td>\n",
       "      <td>32462</td>\n",
       "      <td>xtfjw1ag</td>\n",
       "      <td>998</td>\n",
       "      <td>1.592462</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1</td>\n",
       "      <td>145307</td>\n",
       "      <td>vr7vm64u</td>\n",
       "      <td>999</td>\n",
       "      <td>1.472311</td>\n",
       "      <td>coronavirus origin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    qid   docid     docno  rank     score               query\n",
       "0     1  175892  zy8qjaai     0  7.080599  coronavirus origin\n",
       "1     1   82224  8ccl9aui     1  6.775667  coronavirus origin\n",
       "2     1  135326  ne5r4d4b     2  6.683114  coronavirus origin\n",
       "3     1   93245  hmvo5b0q     3  6.507303  coronavirus origin\n",
       "4     1   84953  ax6v6ham     4  6.483723  coronavirus origin\n",
       "..   ..     ...       ...   ...       ...                 ...\n",
       "995   1  136214  ygnxmcl1   995  1.640752  coronavirus origin\n",
       "996   1   91270  853ipgea   996  1.634118  coronavirus origin\n",
       "997   1  146556  oshov14d   997  1.634118  coronavirus origin\n",
       "998   1   32462  xtfjw1ag   998  1.592462  coronavirus origin\n",
       "999   1  145307  vr7vm64u   999  1.472311  coronavirus origin\n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(cord19.get_topics(variant='title').head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1yCXIB5w1Qb"
   },
   "source": [
    "There many other PyTerrier operators and please see examples in the [PyTerrier documentation on operators](https://pyterrier.readthedocs.io/en/latest/operators.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NaYavGvnxDk5"
   },
   "source": [
    "## Task 1: Pipeline Construction (15 points)\n",
    "\n",
    "Create a ranker that performs the following:\n",
    " - obtains the top 10 highest scoring documents by term frequency (`wmodel=\"Tf\"`)\n",
    " - obtains the top 10 highest scoring documents by TF.IDF (`wmodel=\"TF_IDF\"`)\n",
    " - reranks only those documents found in BOTH of the previous retrieval settings using BM25.\n",
    "\n",
    "How many documents are retrieved by this full pipeline for the query `\"chemical\"`.\n",
    "> If you obtain the correct solution, the document with docno `\"37771\"` should have a score of $12.426309\t$ for query `\"chemical\"`.\n",
    "\n",
    "Hints:\n",
    " - choose carefully your [PyTerrier operators](https://pyterrier.readthedocs.io/en/latest/operators.html)\n",
    " - you should not need to perform any Pandas dataframe operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 634,
     "status": "ok",
     "timestamp": 1616668361281,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "XnsRdT4WvspD"
   },
   "outputs": [],
   "source": [
    "tf = pt.BatchRetrieve(index, wmodel=\"Tf\") % 10\n",
    "tfidf = pt.BatchRetrieve(index, wmodel=\"TF_IDF\") % 10\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = (tf & tfidf) >> bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dershan/opt/anaconda3/lib/python3.8/site-packages/pyterrier/transformer.py:544: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  res = self.transformer.transform(topics_and_res)\n",
      "/Users/dershan/opt/anaconda3/lib/python3.8/site-packages/pyterrier/transformer.py:544: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  res = self.transformer.transform(topics_and_res)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>37771</td>\n",
       "      <td>jn5qi1jb</td>\n",
       "      <td>0</td>\n",
       "      <td>12.426309</td>\n",
       "      <td>chemical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>134305</td>\n",
       "      <td>0smev8vt</td>\n",
       "      <td>1</td>\n",
       "      <td>12.292890</td>\n",
       "      <td>chemical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>142104</td>\n",
       "      <td>77c9ohxj</td>\n",
       "      <td>2</td>\n",
       "      <td>12.226076</td>\n",
       "      <td>chemical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>56631</td>\n",
       "      <td>sps45fj5</td>\n",
       "      <td>3</td>\n",
       "      <td>11.642770</td>\n",
       "      <td>chemical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2524</td>\n",
       "      <td>ifebw24e</td>\n",
       "      <td>4</td>\n",
       "      <td>11.439890</td>\n",
       "      <td>chemical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid   docid     docno  rank      score     query\n",
       "0   1   37771  jn5qi1jb     0  12.426309  chemical\n",
       "1   1  134305  0smev8vt     1  12.292890  chemical\n",
       "2   1  142104  77c9ohxj     2  12.226076  chemical\n",
       "3   1   56631  sps45fj5     3  11.642770  chemical\n",
       "4   1    2524  ifebw24e     4  11.439890  chemical"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(\"chemical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4g8V7Zzpy3g1"
   },
   "source": [
    "## Developing more complex transformers pipelines\n",
    "\n",
    "PyTerrier has a number of useful transformers that we can use to create complex retrieval pipelines. For composing pipelines, let's first define a bit of notation:\n",
    " - $Q$: a set of queries\n",
    " - $D$: a set of documents\n",
    " - $R$: a set of retrieved documents for a set of queries\n",
    "\n",
    "In our setting, we'll use three transformers:\n",
    " - `pt.BatchRetrieve(index, wmodel=\"BM25\")` - input $Q$ or $R$ (retrieval or reranking), output $R$\n",
    " - `pt.rewrite.SDM()` (sequential dependence proximity model) - input $Q$, output $Q$. \n",
    " - `pt.rewrite.Bo1QueryExpansion(index)` - input $R$, output $Q$.\n",
    "\n",
    "Note that now, we're using BM25 instead of TF-IDF to retrieve documents.\n",
    "\n",
    "Transformers like `SDM` are performing query augmentation. Here, `SDM` is reweighting terms using a Dirichlet language model like we talked about in class. However, many query rewrites a possible! For example, we could use WordNet to expand the query with synonyms or even define our own. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 720,
     "status": "ok",
     "timestamp": 1616668415043,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "5nJHxh7A2dPP"
   },
   "outputs": [],
   "source": [
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "sdm = pt.rewrite.SDM()\n",
    "qe = pt.rewrite.Bo1QueryExpansion(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how `sdm` applies to a given query. This generates a query in an [Indri-like query language](https://www.lemurproject.org/lemur/IndriQueryLanguage.php) that Terrier (cf. `pt.BatchRetrieve()`) can understand.\n",
    " - `#combine()` - is used for weighting sub-expressions\n",
    " - `#1() - matches as a phrase, i.e. how many times do the constituent words exactly match as a phrase\n",
    " - `#uw8()` and `#uw12()` look for how many times the constituent words appear in unordered windows of 8 or 12 tokens.\n",
    " - finally, the weighting model is overridden for these query terms.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chemical reactions #combine:0=0.1:wmodel=org.terrier.matching.models.dependence.pBiL(#1(chemical reactions)) #combine:0=0.1:wmodel=org.terrier.matching.models.dependence.pBiL(#uw8(chemical reactions)) #combine:0=0.1:wmodel=org.terrier.matching.models.dependence.pBiL(#uw12(chemical reactions))'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdm.search(\"chemical reactions\").iloc[0][\"query\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVmde7NpJdTT"
   },
   "source": [
    "## Task 2.1: Creating Experiments to test Pipelines (3 points)\n",
    "\n",
    "Which kinds of rankers will perform better? We can answer this by creating an [Experiment](https://pyterrier.readthedocs.io/en/latest/experiments.html) that will compare sequential dependence model and Bo1 query expansion on TREC CORD19 with the BM25 baseline. We used Experiments in Part 1, so we'll expand this idea again here to test out different pipelines.\n",
    "\n",
    "**Your Task:** You will need to construct appropriate pipelines to compare each approach by considering the input and output datatypes of the `bm25`, `sdm` and `qe`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 927,
     "status": "ok",
     "timestamp": 1616668451894,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "TF24TZSb3bOo"
   },
   "outputs": [],
   "source": [
    "topics = cord19.get_topics(variant='title')\n",
    "qrels = cord19.get_qrels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdm_pipe = sdm >> bm25\n",
    "qe_pipe = bm25 >> qe >> bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 648,
     "status": "ok",
     "timestamp": 1616668453463,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "eqXox-g-JpUd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>ndcg_cut_5</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BR(BM25)</td>\n",
       "      <td>0.181478</td>\n",
       "      <td>0.373328</td>\n",
       "      <td>0.611724</td>\n",
       "      <td>0.583665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Compose(&lt;pyterrier.rewrite.SDM object at 0x2ab...</td>\n",
       "      <td>0.181982</td>\n",
       "      <td>0.373439</td>\n",
       "      <td>0.613116</td>\n",
       "      <td>0.586512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Compose(Compose(BR(BM25), &lt;pyterrier.rewrite.B...</td>\n",
       "      <td>0.190398</td>\n",
       "      <td>0.388397</td>\n",
       "      <td>0.619323</td>\n",
       "      <td>0.580906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name       map      ndcg  \\\n",
       "0                                           BR(BM25)  0.181478  0.373328   \n",
       "1  Compose(<pyterrier.rewrite.SDM object at 0x2ab...  0.181982  0.373439   \n",
       "2  Compose(Compose(BR(BM25), <pyterrier.rewrite.B...  0.190398  0.388397   \n",
       "\n",
       "   ndcg_cut_5  ndcg_cut_10  \n",
       "0    0.611724     0.583665  \n",
       "1    0.613116     0.586512  \n",
       "2    0.619323     0.580906  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    [bm25, sdm_pipe, qe_pipe],\n",
    "    topics,\n",
    "    qrels,\n",
    "    eval_metrics=[\"map\", \"ndcg\", \"ndcg_cut_5\", \"ndcg_cut_10\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2:  Reflection (2 points)\n",
    "\n",
    "Which approaches result in significant increases in NDCG and MAP? Is NDCG@10 also improved? Write 2-3 sentences why you think this is the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B01 query expansion paired with BM25 had the best performance in terms of NDCG and MAP. However, its NDCG@10 score is the lowest among the three. This could be because there are a couple less relevant documents positioned in the front, but overall query expansion still provided a pretty decent ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aJrYP1TSLwY"
   },
   "source": [
    "# Learning to Rank\n",
    "\n",
    "Now that we have some idea how to build pipelines in PyTerrier, we'll continue our exploration by constructing and evaluating Learning to Rank pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSi3svV24mCs"
   },
   "source": [
    "Learning to rank is fundamentally a machine learning approach to IR. To work, we'll need to create _training data_ to learn our ranking model. We'll also want development (\"dev\") data to evaluate hyperparameters and test data to see how well it works. Our dataset doesn't by itself already have the data split into train, dev, and test, so we'll first need to do that.\n",
    "\n",
    "TREC Covid only has 50 topics, which isn't a lot for training in general. However, for a homework, 50 is sufficient to show you how it works. In this case, we'll split this 30 for training (60%), 5 for validation (10%), and 15 for evaluation (30%). In your projects, you'll want to test for statistical significance (i.e., is the improvement better than what could be expected by chance?) so we will also examine statistical significance, though we have limited data (15 topics) to do this with.\n",
    "\n",
    "When training our model, we will only re-rank the top 500 documents for each query, which is hopefully sufficient data for learning to rank. We don't set the model to rerank _all_ documents (though you can try this!) since it causes us to have to train the Learning to Rank model on all data and is often very slow in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 889,
     "status": "ok",
     "timestamp": 1616668500768,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "INvVKQz6K7SB"
   },
   "outputs": [],
   "source": [
    "RANK_CUTOFF = 10\n",
    "SEED=42\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tr_va_topics, test_topics = train_test_split(topics, test_size=15, random_state=SEED)\n",
    "train_topics, valid_topics =  train_test_split(tr_va_topics, test_size=5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vftc_y-65VfA"
   },
   "source": [
    "## Defining a Feature Set for Learning to Rank\n",
    "\n",
    "Learning to Rank requires that we define which features to use in determining a ranking. We can use scores like BM25 but it's common to try adding more complex features that take advantage of what you, the IR practitioner, knows about the data or features that would be useful.\n",
    "\n",
    "For this part, we'll start with 7 features. PyTerrier provides [extensive support](https://pyterrier.readthedocs.io/en/latest/ltr.html#) for how to define features and calculate them for Learning to Rank. We recommend reading that documentation as you start to go over the code below. Note that several of these features will use more than just the text to compute relevance!\n",
    "\n",
    "1.   the BM25 abstract score;\n",
    "2.   sequential dependence model, scored by BM25;\n",
    "3.   does the abstract contain 'coronavirus covid', scored by BM25;\n",
    "4.   the BM25 score on the title (even though we didn't index it earlier!);\n",
    "5.   was the paper released/published in 2020? Recent papers were more useful for this task;\n",
    "6.   does the paper have a DOI, i.e. is it a formal publication?\n",
    "7.   the coordinate match score for the query--i.e. how many query terms appear in the abstract.\n",
    "\n",
    "Several of these feature require additional metadata `[\"title\", \"date\", \"doi\"]`, which is present in the TREC covid dataset. Fortunately, we can obtain this metadata after indexing using `pt.text.get_text(cord19, [\"title\", \"date\", \"doi\"])` to retrieve these extra metadata columns from the original data.\n",
    "\n",
    "There is a lot going on in this code block, but it's useful to think of this as _another_ example of operator overloading in PyTerrier. Here, we're combining features using the `**` operator, which is the [feature union](https://pyterrier.readthedocs.io/en/latest/ltr.html#calculating-features) operator in PyTerrier. \n",
    "\n",
    "The output of our feature union is the `ltr_feats1` object which is itself a transformer we can use to start ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 634,
     "status": "ok",
     "timestamp": 1616668557695,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "AYgwwrsPTGP1"
   },
   "outputs": [],
   "source": [
    "ltr_feats1 = (bm25 % RANK_CUTOFF) >> pt.text.get_text(cord19, [\"title\", \"date\", \"doi\"]) >> (\n",
    "    pt.transformer.IdentityTransformer()\n",
    "    ** # sequential dependence\n",
    "    (sdm >> bm25)\n",
    "    ** # score of text for query 'coronavirus covid'\n",
    "    (pt.apply.query(lambda row: 'coronavirus covid') >> bm25)\n",
    "    ** # score of title (not originally indexed)\n",
    "    (pt.text.scorer(body_attr=\"title\", takes='docs', wmodel='BM25')) \n",
    "    ** # date 2020\n",
    "    (pt.apply.doc_score(lambda row: int(\"2020\" in row[\"date\"])))\n",
    "    ** # has doi\n",
    "    (pt.apply.doc_score(lambda row: int(row[\"doi\"] is not None and len(row[\"doi\"]) > 0)))\n",
    "    ** # abstract coordinate match\n",
    "    pt.BatchRetrieve(index, wmodel=\"CoordinateMatch\")\n",
    ")\n",
    "\n",
    "# for reference, lets record the feature names here too\n",
    "fnames=[\"BM25\", \"SDM\", 'coronavirus covid', 'title', \"2020\", \"hasDoi\", \"CoordinateMatch\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nu3M9ujw6trC"
   },
   "source": [
    "To get a sense of what this process is doing, let's look at the output for the query \"coronavirus origin\". We can see that we now have extra document metadata columns `[\"title\", \"date\", \"doi\"]`, as well as the `\"features\"` column, which is what we'll use for learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "executionInfo": {
     "elapsed": 1000,
     "status": "ok",
     "timestamp": 1616668567796,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "OMG9kK9AUWI4",
    "outputId": "e4f6cbf8-4e89-46c8-b6c7-8d3e75eac2f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:04:24.568 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>doi</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>175892</td>\n",
       "      <td>zy8qjaai</td>\n",
       "      <td>0</td>\n",
       "      <td>11.915479</td>\n",
       "      <td>coronavirus origin</td>\n",
       "      <td>The battle against SARS and MERS coronaviruses...</td>\n",
       "      <td>2018-07-28</td>\n",
       "      <td>10.1002/ame2.12017</td>\n",
       "      <td>[11.915479443193252, 12.058058237271272, 4.066...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>82224</td>\n",
       "      <td>8ccl9aui</td>\n",
       "      <td>1</td>\n",
       "      <td>11.550953</td>\n",
       "      <td>coronavirus origin</td>\n",
       "      <td>Mosaic evolution of the severe acute respirato...</td>\n",
       "      <td>2004</td>\n",
       "      <td></td>\n",
       "      <td>[11.55095262556724, 11.69464350657987, 3.18074...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>135326</td>\n",
       "      <td>ne5r4d4b</td>\n",
       "      <td>2</td>\n",
       "      <td>11.268729</td>\n",
       "      <td>coronavirus origin</td>\n",
       "      <td>Origin and evolution of pathogenic coronaviruses</td>\n",
       "      <td>2018-12-10</td>\n",
       "      <td>10.1038/s41579-018-0118-9</td>\n",
       "      <td>[11.26872908286073, 11.26872908286073, 3.73231...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>122804</td>\n",
       "      <td>75773gwg</td>\n",
       "      <td>3</td>\n",
       "      <td>11.165944</td>\n",
       "      <td>coronavirus origin</td>\n",
       "      <td>Zoonotic origins of human coronavirus 2019 (HC...</td>\n",
       "      <td>2020</td>\n",
       "      <td></td>\n",
       "      <td>[11.165943985807157, 11.165943985807157, 5.567...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>122805</td>\n",
       "      <td>kn2z7lho</td>\n",
       "      <td>4</td>\n",
       "      <td>11.165944</td>\n",
       "      <td>coronavirus origin</td>\n",
       "      <td>Zoonotic origins of human coronavirus 2019 (HC...</td>\n",
       "      <td>2020</td>\n",
       "      <td></td>\n",
       "      <td>[11.165943985807157, 11.165943985807157, 5.567...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>122806</td>\n",
       "      <td>4fb291hq</td>\n",
       "      <td>5</td>\n",
       "      <td>11.165944</td>\n",
       "      <td>coronavirus origin</td>\n",
       "      <td>Zoonotic origins of human coronavirus 2019 (HC...</td>\n",
       "      <td>2020</td>\n",
       "      <td></td>\n",
       "      <td>[11.165943985807157, 11.165943985807157, 5.567...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>187888</td>\n",
       "      <td>hl967ekh</td>\n",
       "      <td>6</td>\n",
       "      <td>11.165944</td>\n",
       "      <td>coronavirus origin</td>\n",
       "      <td>Zoonotic origins of human coronavirus 2019 (HC...</td>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>10.24272/j.issn.2095-8137.2020.031</td>\n",
       "      <td>[11.165943985807157, 11.165943985807157, 5.567...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>109967</td>\n",
       "      <td>kgifmjvb</td>\n",
       "      <td>7</td>\n",
       "      <td>10.982382</td>\n",
       "      <td>coronavirus origin</td>\n",
       "      <td>Tracking the origin of early COVID-19 cases in...</td>\n",
       "      <td>2020</td>\n",
       "      <td></td>\n",
       "      <td>[10.98238225417628, 11.125659067727756, 5.6850...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>93245</td>\n",
       "      <td>hmvo5b0q</td>\n",
       "      <td>8</td>\n",
       "      <td>10.968774</td>\n",
       "      <td>coronavirus origin</td>\n",
       "      <td>Understanding Coronavirus</td>\n",
       "      <td>2020</td>\n",
       "      <td></td>\n",
       "      <td>[10.968774450337538, 11.111910932288065, 5.618...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>135870</td>\n",
       "      <td>wmfcey6f</td>\n",
       "      <td>9</td>\n",
       "      <td>10.955257</td>\n",
       "      <td>coronavirus origin</td>\n",
       "      <td>Tracking the origin of early COVID-19 cases in...</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>10.1016/j.ijid.2020.05.046</td>\n",
       "      <td>[10.955256957587741, 11.098547246854947, 5.669...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid   docid     docno  rank      score               query  \\\n",
       "0   1  175892  zy8qjaai     0  11.915479  coronavirus origin   \n",
       "1   1   82224  8ccl9aui     1  11.550953  coronavirus origin   \n",
       "2   1  135326  ne5r4d4b     2  11.268729  coronavirus origin   \n",
       "3   1  122804  75773gwg     3  11.165944  coronavirus origin   \n",
       "4   1  122805  kn2z7lho     4  11.165944  coronavirus origin   \n",
       "5   1  122806  4fb291hq     5  11.165944  coronavirus origin   \n",
       "6   1  187888  hl967ekh     6  11.165944  coronavirus origin   \n",
       "7   1  109967  kgifmjvb     7  10.982382  coronavirus origin   \n",
       "8   1   93245  hmvo5b0q     8  10.968774  coronavirus origin   \n",
       "9   1  135870  wmfcey6f     9  10.955257  coronavirus origin   \n",
       "\n",
       "                                               title        date  \\\n",
       "0  The battle against SARS and MERS coronaviruses...  2018-07-28   \n",
       "1  Mosaic evolution of the severe acute respirato...        2004   \n",
       "2   Origin and evolution of pathogenic coronaviruses  2018-12-10   \n",
       "3  Zoonotic origins of human coronavirus 2019 (HC...        2020   \n",
       "4  Zoonotic origins of human coronavirus 2019 (HC...        2020   \n",
       "5  Zoonotic origins of human coronavirus 2019 (HC...        2020   \n",
       "6  Zoonotic origins of human coronavirus 2019 (HC...  2020-05-16   \n",
       "7  Tracking the origin of early COVID-19 cases in...        2020   \n",
       "8                          Understanding Coronavirus        2020   \n",
       "9  Tracking the origin of early COVID-19 cases in...  2020-05-17   \n",
       "\n",
       "                                  doi  \\\n",
       "0                  10.1002/ame2.12017   \n",
       "1                                       \n",
       "2           10.1038/s41579-018-0118-9   \n",
       "3                                       \n",
       "4                                       \n",
       "5                                       \n",
       "6  10.24272/j.issn.2095-8137.2020.031   \n",
       "7                                       \n",
       "8                                       \n",
       "9          10.1016/j.ijid.2020.05.046   \n",
       "\n",
       "                                            features  \n",
       "0  [11.915479443193252, 12.058058237271272, 4.066...  \n",
       "1  [11.55095262556724, 11.69464350657987, 3.18074...  \n",
       "2  [11.26872908286073, 11.26872908286073, 3.73231...  \n",
       "3  [11.165943985807157, 11.165943985807157, 5.567...  \n",
       "4  [11.165943985807157, 11.165943985807157, 5.567...  \n",
       "5  [11.165943985807157, 11.165943985807157, 5.567...  \n",
       "6  [11.165943985807157, 11.165943985807157, 5.567...  \n",
       "7  [10.98238225417628, 11.125659067727756, 5.6850...  \n",
       "8  [10.968774450337538, 11.111910932288065, 5.618...  \n",
       "9  [10.955256957587741, 11.098547246854947, 5.669...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltr_feats1.search(\"coronavirus origin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vQNbSSgJCmC"
   },
   "source": [
    "We can also look at the raw feature values themselves too. Here, we'll look at the features for the first document. Note that the BM25 in the \"score\" column above is also the first value in the feature array (20.54), because we used an identity transformer, which returns the same value as its input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1006,
     "status": "ok",
     "timestamp": 1616668573072,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "EzVDLL8pI_gR",
    "outputId": "ff60a8d3-ebc0-4d1b-b87d-0e6245ad7553"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:38:32.123 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([20.54147667, 20.54147667,  2.89976767,  0.        ,  1.        ,\n",
       "        1.        ,  1.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltr_feats1.search(\"coronovirus origin\").iloc[0][\"features\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Od8P-N4E7QTk"
   },
   "source": [
    "## Actually Doing the Learning for Learning to Rank\n",
    "\n",
    "In class, we talked about three types of Learning to rank: pointwise, pairwise, and listwise. Here, we'll train a few models for two of these types, listwise and pointwise. \n",
    "\n",
    " - coordinate ascent from FastRank, a listwise linear technique\n",
    " - random forests from `scikit-learn`, a pointwise regression tree technique\n",
    " - LambdaMART from LightGBM, a listwise regression tree technique\n",
    "\n",
    "We can use the same feature pipeline, `ltr_feats1`, with all three.  To train the ranker, we compose it (`>>`) with the learned model. We use `pt.ltr.apply_learned_model()` which knows how to deal with different learners.\n",
    "\n",
    "The full pipeline is then fitted (learned) using `.fit()`, specifying the training topics and qrels, much like how we train models with Scikit-Learn. Importantly, the preceding stages of the pipeline (retrieval and feature calculation) are applied to the training topics in order to obtain the results, which are then passed to the learning to rank technique. LightGBM has early stopping enabled, which uses a validation topics set--similarly the validation topics are transformed into validation results.\n",
    "\n",
    "Finally, `%time` is notebook \"magic command\" specific to Juypyter which displays how long learning takes for each technique. Learning for each technique takes under 30 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23178,
     "status": "ok",
     "timestamp": 1616668669944,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "OFPZ39eSYIXV",
    "outputId": "0c3e398c-ae14-4fce-8d94-703151d53ad0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:45:31.614 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/techen/.local/lib/python3.8/site-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from <pyterrier.batchretrieve.TextScorer object at 0x2b408273ebe0>, expected 300 received 304, feature scores for any missing documents be 0, extraneous documents will be removed\n",
      "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.8 s, sys: 595 ms, total: 59.4 s\n",
      "Wall time: 29.6 s\n"
     ]
    }
   ],
   "source": [
    "import fastrank\n",
    "\n",
    "train_request = fastrank.TrainRequest.coordinate_ascent()\n",
    "\n",
    "params = train_request.params\n",
    "params.init_random = True\n",
    "params.normalize = True\n",
    "params.seed = 1234567\n",
    "\n",
    "ca_pipe = ltr_feats1 >> pt.ltr.apply_learned_model(train_request, form='fastrank')\n",
    "\n",
    "%time ca_pipe.fit(train_topics, cord19.get_qrels())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try learning a different pointwise model to estimate relevance scores using a Random Forest model from Scikit-Learn. This is a good example of how we can use off-the-shelf regression models in PyTerrier to perform learning to rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9897,
     "status": "ok",
     "timestamp": 1616668679862,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "T0SpZ13wUagq",
    "outputId": "c3fdfa85-bad7-47d0-b95b-f51ba9d35efb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:45:55.351 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/techen/.local/lib/python3.8/site-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from <pyterrier.batchretrieve.TextScorer object at 0x2b408273ebe0>, expected 300 received 304, feature scores for any missing documents be 0, extraneous documents will be removed\n",
      "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.1 s, sys: 672 ms, total: 13.8 s\n",
      "Wall time: 9.98 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    4.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=400, verbose=1, random_state=SEED, n_jobs=2)\n",
    "\n",
    "rf_pipe = ltr_feats1 >> pt.ltr.apply_learned_model(rf)\n",
    "\n",
    "%time rf_pipe.fit(train_topics, cord19.get_qrels())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's use a list-wise approach, which typically performs best among the three types of Learning to Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8930,
     "status": "ok",
     "timestamp": 1616668695125,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "u0jb1jw_VdWU",
    "outputId": "1d658e08-07d7-4753-cc79-a987ebafc6ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:46:06.931 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/techen/.local/lib/python3.8/site-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from <pyterrier.batchretrieve.TextScorer object at 0x2b408273ebe0>, expected 300 received 304, feature scores for any missing documents be 0, extraneous documents will be removed\n",
      "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:46:09.592 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/techen/.local/lib/python3.8/site-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from <pyterrier.batchretrieve.TextScorer object at 0x2b408273ebe0>, expected 50 received 54, feature scores for any missing documents be 0, extraneous documents will be removed\n",
      "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 351\n",
      "[LightGBM] [Info] Number of data points in the train set: 65832, number of used features: 7\n",
      "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[1]\tvalid_0's ndcg@10: 0.852789\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[2]\tvalid_0's ndcg@10: 0.852789\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[3]\tvalid_0's ndcg@10: 0.852789\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[4]\tvalid_0's ndcg@10: 0.852789\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[5]\tvalid_0's ndcg@10: 0.852789\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[6]\tvalid_0's ndcg@10: 0.852789\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@10: 0.852789\n",
      "CPU times: user 9.14 s, sys: 1.43 s, total: 10.6 s\n",
      "Wall time: 9.64 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/techen/.local/lib/python3.8/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/techen/.local/lib/python3.8/site-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# this configures LightGBM as LambdaMART\n",
    "lmart_l = lgb.LGBMRanker(\n",
    "    task=\"train\",\n",
    "    silent=False,\n",
    "    min_data_in_leaf=1,\n",
    "    min_sum_hessian_in_leaf=1,\n",
    "    max_bin=255,\n",
    "    num_leaves=31,\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    ndcg_eval_at=[10],\n",
    "    ndcg_at=[10],\n",
    "    eval_at=[10],\n",
    "    learning_rate= .1,\n",
    "    importance_type=\"gain\",\n",
    "    num_iterations=100,\n",
    "    early_stopping_rounds=5\n",
    ")\n",
    "\n",
    "lmart_x_pipe = ltr_feats1 >> pt.ltr.apply_learned_model(lmart_l, form=\"ltr\", fit_kwargs={'eval_at':[10]})\n",
    "\n",
    "%time lmart_x_pipe.fit(train_topics, cord19.get_qrels(), valid_topics, cord19.get_qrels())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7rNqB7sBKFB"
   },
   "source": [
    "## Evaluating all the solutions \n",
    "\n",
    "We've fit the three Learning to Rank models so we can now use them to predict relevance scores for the held-out 15 topics (queries) in our test set. Note that if we wanted to do any tuning (e.g., pick the number of leaves in our `RandomForestRegressor`, we could run this evaluation on our held-out _dev_ set and pick the hyperparameters that produced best performance on it).\n",
    "\n",
    "### Task 3: Create an experiment to compare (5 points)\n",
    "\n",
    "Create a new `Experiment` to compare our three solutions and BM25 at the `RANK_CUTOFF` (four models in total). Report MAP, NDCG, and NDCG@10 measures and one new measure: mean response time (`\"mrt\"`), which will tell us how fast the models are able to score documents--something important if we're going to use them in the real world!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "executionInfo": {
     "elapsed": 8964,
     "status": "ok",
     "timestamp": 1616668732099,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "P0EhTwejVqev",
    "outputId": "3393cb4e-2a2e-4e92-ede5-5857457ca863"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:58:06.180 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
      "13:58:07.777 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:58:09.499 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "      <th>mrt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Compose(Compose(Compose(RankCutoff(BR(BM25), 1...</td>\n",
       "      <td>0.012253</td>\n",
       "      <td>0.049092</td>\n",
       "      <td>0.580835</td>\n",
       "      <td>217.216858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Compose(Compose(Compose(RankCutoff(BR(BM25), 1...</td>\n",
       "      <td>0.011271</td>\n",
       "      <td>0.045830</td>\n",
       "      <td>0.551404</td>\n",
       "      <td>112.977960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Compose(Compose(Compose(RankCutoff(BR(BM25), 1...</td>\n",
       "      <td>0.009926</td>\n",
       "      <td>0.042458</td>\n",
       "      <td>0.528034</td>\n",
       "      <td>104.096169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RankCutoff(BR(BM25), 10)</td>\n",
       "      <td>0.010480</td>\n",
       "      <td>0.043844</td>\n",
       "      <td>0.537236</td>\n",
       "      <td>48.512402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name       map      ndcg  \\\n",
       "0  Compose(Compose(Compose(RankCutoff(BR(BM25), 1...  0.012253  0.049092   \n",
       "1  Compose(Compose(Compose(RankCutoff(BR(BM25), 1...  0.011271  0.045830   \n",
       "2  Compose(Compose(Compose(RankCutoff(BR(BM25), 1...  0.009926  0.042458   \n",
       "3                           RankCutoff(BR(BM25), 10)  0.010480  0.043844   \n",
       "\n",
       "   ndcg_cut_10         mrt  \n",
       "0     0.580835  217.216858  \n",
       "1     0.551404  112.977960  \n",
       "2     0.528034  104.096169  \n",
       "3     0.537236   48.512402  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    [ca_pipe, rf_pipe, lmart_x_pipe, (bm25 % RANK_CUTOFF)],\n",
    "    test_topics,\n",
    "    qrels, \n",
    "    eval_metrics=[\"map\", \"ndcg\", \"ndcg_cut_10\", \"mrt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmGe5rniC_Pn"
   },
   "source": [
    "Thats really interesting – all three learned models could improve NDCG@10 over BM25, but the coordinate ascent model improved the most (significantly so on all three metrics, but again on only 15 queries). Coordinate Ascent improved upto 10 queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ov0JjWGEbrT"
   },
   "source": [
    "## Analysis: What Features Matter?\n",
    "\n",
    "Since we're _learning_ a ranking model, we can inspect that model to see what information it's using. One option for inspecting the model is to evaluate the performance of each feature independently to see how much it contributes to the eventual relevance. To examine each feature, we will create separate a separate model from each feature in our feature pipeline (`ltr_feats1`) by using `pt.ltr.feature_to_score(i)` with a particular feature number $i$. In essence, this will only score the relevance using a single feature's values, even though we've already calculated all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "executionInfo": {
     "elapsed": 17063,
     "status": "ok",
     "timestamp": 1616668775186,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "7nCb9U7uvszV",
    "outputId": "ea79739f-9155-4343-9f7d-62a5d523ebcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09:00:18.787 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
      "09:00:20.426 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
      "09:00:22.065 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
      "09:00:23.714 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
      "09:00:25.352 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
      "09:00:27.044 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
      "09:00:28.749 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "      <th>num_rel_ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.010480</td>\n",
       "      <td>0.043844</td>\n",
       "      <td>0.537236</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SDM</td>\n",
       "      <td>0.010429</td>\n",
       "      <td>0.043568</td>\n",
       "      <td>0.535770</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coronavirus covid</td>\n",
       "      <td>0.011637</td>\n",
       "      <td>0.046777</td>\n",
       "      <td>0.562223</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>title</td>\n",
       "      <td>0.011799</td>\n",
       "      <td>0.047354</td>\n",
       "      <td>0.567363</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.011064</td>\n",
       "      <td>0.045604</td>\n",
       "      <td>0.555846</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hasDoi</td>\n",
       "      <td>0.009928</td>\n",
       "      <td>0.042970</td>\n",
       "      <td>0.531974</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CoordinateMatch</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.044333</td>\n",
       "      <td>0.540893</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name       map      ndcg  ndcg_cut_10  num_rel_ret\n",
       "0               BM25  0.010480  0.043844     0.537236         95.0\n",
       "1                SDM  0.010429  0.043568     0.535770         95.0\n",
       "2  coronavirus covid  0.011637  0.046777     0.562223         95.0\n",
       "3              title  0.011799  0.047354     0.567363         95.0\n",
       "4               2020  0.011064  0.045604     0.555846         95.0\n",
       "5             hasDoi  0.009928  0.042970     0.531974         95.0\n",
       "6    CoordinateMatch  0.010742  0.044333     0.540893         95.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    [ltr_feats1 >> pt.ltr.feature_to_score(i) for i in range(len(fnames))],\n",
    "    test_topics,\n",
    "    qrels, \n",
    "    names=fnames,\n",
    "    eval_metrics=[\"map\", \"ndcg\", \"ndcg_cut_10\", \"num_rel_ret\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rU7YYKFSFeke"
   },
   "source": [
    "### Inspecting the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjaWBEo8HA20"
   },
   "source": [
    "To get a sense of feature importance, we can also analyze the learned models themselves using their internal feature weights in the Scikit-Learn models. Here, we'll plot the feature importances in a few ways. For the coordinate ascent model, we plot the feature weights (note the log-scale y-axis); while for the regression-tree based techniques, we report the feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "executionInfo": {
     "elapsed": 2333,
     "status": "ok",
     "timestamp": 1616668777541,
     "user": {
      "displayName": "Nicola Tonellotto",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64",
      "userId": "17533833776178224794"
     },
     "user_tz": -60
    },
    "id": "CdOP1b8Cjp44",
    "outputId": "e2da7f44-21de-4fc0-a6f5-50c3285b6525"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-72f0db59652a>:22: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt, numpy as np\n",
    "\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(10, 6))\n",
    "\n",
    "ax0.bar(np.arange(len(fnames)), ca_pipe[1].model.to_dict()['Linear']['weights'])\n",
    "ax0.set_xticks(np.arange(len(fnames)))\n",
    "ax0.set_xticklabels(fnames, rotation=45, ha='right')\n",
    "ax0.set_title(\"Coordinate Ascent\\n Feature Weights\")\n",
    "ax0.set_yscale('log')\n",
    "\n",
    "ax1.bar(np.arange(len(fnames)), rf.feature_importances_)\n",
    "ax1.set_xticks(np.arange(len(fnames)))\n",
    "ax1.set_xticklabels(fnames, rotation=45, ha='right')\n",
    "ax1.set_title(\"Random Forests\\n Feature Importance\")\n",
    "\n",
    "ax2.bar(np.arange(len(fnames)), lmart_l.feature_importances_)\n",
    "ax2.set_xticks(np.arange(len(fnames)))\n",
    "ax2.set_xticklabels(fnames, rotation=45, ha='right')\n",
    "ax2.set_title(\"$\\lambda$MART\\n Feature Importance\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HhGDiPLHO7v"
   },
   "source": [
    "## Task 4: Adding new features (15 points)\n",
    "\n",
    "We've seen how to develop Learning to Rank models and analyze features. Your task is the following:\n",
    "\n",
    "  - Define _at least_ two additional features to use in learning to rank models. These can be functions that you define or additional options from PyTerrier\n",
    "  - Include your new features in a new learning to rank pipeline using the three approaches we have above to create three new models\n",
    "  - Evaluate your new models against the old models in an Experiment\n",
    " \n",
    "**Full credit will depend on one of your new models outperforming the best of the initial three models.**\n",
    "\n",
    "You should aim to evaluate your features initially on the `dev` set, rather than the `test` set in order to avoid overfitting your features (i.e., never look at the test set until the end). You can use the feature and model inspection code to give you some idea of what the model is looking at. We also recommend looking at the data directly to think about what kinds of features might be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltr_feats2 = (bm25 % RANK_CUTOFF) >> pt.text.get_text(cord19, [\"title\", \"date\", \"doi\"]) >> (\n",
    "    pt.transformer.IdentityTransformer()\n",
    "    ** # sequential dependence\n",
    "    (sdm >> bm25)\n",
    "    ** # score of text for query 'coronavirus covid'\n",
    "    (pt.apply.query(lambda row: 'coronavirus covid') >> bm25)\n",
    "    ** # score of text for query 'pandemic disease infection'\n",
    "    (pt.apply.query(lambda row: 'pandemic disease infection') >> bm25)\n",
    "    ** # score of text for query 'mrna vaccine'\n",
    "    (pt.apply.query(lambda row: 'mrna vaccine') >> bm25)\n",
    "    ** # score of title (not originally indexed)\n",
    "    (pt.text.scorer(body_attr=\"title\", takes='docs', wmodel='BM25'))\n",
    "    ** # date 2020\n",
    "    (pt.apply.doc_score(lambda row: int(\"2020\" in row[\"date\"])))\n",
    "    ** # has doi\n",
    "    (pt.apply.doc_score(lambda row: int( row[\"doi\"] is not None and len(row[\"doi\"]) > 0)))\n",
    "    ** # abstract coordinate match\n",
    "    (pt.BatchRetrieve(index, wmodel=\"CoordinateMatch\"))\n",
    ")\n",
    "\n",
    "# for reference, lets record the feature names here too\n",
    "fnames_new=[\"BM25\", \"SDM\", 'coronavirus covid', \"pandemic\", 'title_bm25', 'title_dph', \"2020\", \"hasDoi\", \"CoordinateMatch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:07:39.332 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/techen/.local/lib/python3.8/site-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from <pyterrier.batchretrieve.TextScorer object at 0x2b4086fe5340>, expected 300 received 304, feature scores for any missing documents be 0, extraneous documents will be removed\n",
      "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21min 16s, sys: 2.34 s, total: 21min 19s\n",
      "Wall time: 8min 16s\n"
     ]
    }
   ],
   "source": [
    "train_request_new = fastrank.TrainRequest.coordinate_ascent()\n",
    "\n",
    "params_new = train_request_new.params\n",
    "params_new.init_random = True\n",
    "params_new.normalize = True\n",
    "params_new.seed = 1234567\n",
    "\n",
    "ca_pipe_new = ltr_feats2 >> pt.ltr.apply_learned_model(train_request_new, form='fastrank')\n",
    "\n",
    "%time ca_pipe_new.fit(train_topics, cord19.get_qrels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:15:55.638 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/techen/.local/lib/python3.8/site-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from <pyterrier.batchretrieve.TextScorer object at 0x2b4086fe5340>, expected 300 received 304, feature scores for any missing documents be 0, extraneous documents will be removed\n",
      "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:   41.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 8s, sys: 2.4 s, total: 3min 10s\n",
      "Wall time: 1min 46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "rf_new = RandomForestRegressor(n_estimators=400, verbose=1, random_state=SEED, n_jobs=2)\n",
    "rf_pipe_new = ltr_feats2 >> pt.ltr.apply_learned_model(rf_new)\n",
    "\n",
    "%time rf_pipe_new.fit(train_topics, cord19.get_qrels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:04:39.990 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/techen/.local/lib/python3.8/site-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from <pyterrier.batchretrieve.TextScorer object at 0x2b4086fe5340>, expected 300 received 304, feature scores for any missing documents be 0, extraneous documents will be removed\n",
      "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:04:55.317 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/techen/.local/lib/python3.8/site-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from <pyterrier.batchretrieve.TextScorer object at 0x2b4086fe5340>, expected 50 received 54, feature scores for any missing documents be 0, extraneous documents will be removed\n",
      "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n",
      "/home/techen/.local/lib/python3.8/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/techen/.local/lib/python3.8/site-packages/lightgbm/engine.py:156: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008786 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 115\n",
      "[LightGBM] [Info] Number of data points in the train set: 1048872, number of used features: 9\n",
      "[LightGBM] [Warning] early_stopping_round is set=5, early_stopping_rounds=5 will be ignored. Current value: early_stopping_round=5\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[1]\tvalid_0's ndcg@10: 0.852789\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[2]\tvalid_0's ndcg@10: 0.852789\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[3]\tvalid_0's ndcg@10: 0.852789\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[4]\tvalid_0's ndcg@10: 0.852789\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[5]\tvalid_0's ndcg@10: 0.852789\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[6]\tvalid_0's ndcg@10: 0.852789\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@10: 0.852789\n",
      "CPU times: user 43.1 s, sys: 3.84 s, total: 46.9 s\n",
      "Wall time: 42.2 s\n"
     ]
    }
   ],
   "source": [
    "lmart_l_new = lgb.LGBMRanker(\n",
    "    task=\"train\",\n",
    "    silent=False,\n",
    "    min_data_in_leaf=1,\n",
    "    min_sum_hessian_in_leaf=1,\n",
    "    max_bin=255,\n",
    "    num_leaves=31,\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    ndcg_eval_at=[10],\n",
    "    ndcg_at=[10],\n",
    "    eval_at=[10],\n",
    "    learning_rate= .1,\n",
    "    importance_type=\"gain\",\n",
    "    num_iterations=100,\n",
    "    early_stopping_rounds=5\n",
    ")\n",
    "\n",
    "lmart_x_pipe_new = ltr_feats2 >> pt.ltr.apply_learned_model(lmart_l_new, form=\"ltr\", fit_kwargs={'eval_at':[10]})\n",
    "\n",
    "%time lmart_x_pipe_new.fit(train_topics, cord19.get_qrels(), valid_topics, cord19.get_qrels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:17:38.035 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/techen/.local/lib/python3.8/site-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from <pyterrier.batchretrieve.TextScorer object at 0x2b408273ebe0>, expected 50 received 54, feature scores for any missing documents be 0, extraneous documents will be removed\n",
      "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:17:40.284 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/techen/.local/lib/python3.8/site-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from <pyterrier.batchretrieve.TextScorer object at 0x2b4086fe5340>, expected 50 received 54, feature scores for any missing documents be 0, extraneous documents will be removed\n",
      "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:18:00.432 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/techen/.local/lib/python3.8/site-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from <pyterrier.batchretrieve.TextScorer object at 0x2b408273ebe0>, expected 50 received 54, feature scores for any missing documents be 0, extraneous documents will be removed\n",
      "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:18:02.673 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/techen/.local/lib/python3.8/site-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from <pyterrier.batchretrieve.TextScorer object at 0x2b4086fe5340>, expected 50 received 54, feature scores for any missing documents be 0, extraneous documents will be removed\n",
      "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:18:23.853 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/techen/.local/lib/python3.8/site-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from <pyterrier.batchretrieve.TextScorer object at 0x2b408273ebe0>, expected 50 received 54, feature scores for any missing documents be 0, extraneous documents will be removed\n",
      "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:18:25.756 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/techen/.local/lib/python3.8/site-packages/pyterrier/transformer.py:760: UserWarning: Got number of results different expected from <pyterrier.batchretrieve.TextScorer object at 0x2b4086fe5340>, expected 50 received 54, feature scores for any missing documents be 0, extraneous documents will be removed\n",
      "  warn(\"Got number of results different expected from %s, expected %d received %d, feature scores for any missing documents be 0, extraneous documents will be removed\" % (repr(m), num_results, len(res)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "      <th>mrt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Compose(Compose(Compose(RankCutoff(BR(BM25), 1...</td>\n",
       "      <td>0.017341</td>\n",
       "      <td>0.064571</td>\n",
       "      <td>0.704892</td>\n",
       "      <td>379.139772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Compose(Compose(Compose(RankCutoff(BR(BM25), 1...</td>\n",
       "      <td>0.017610</td>\n",
       "      <td>0.066213</td>\n",
       "      <td>0.724416</td>\n",
       "      <td>3681.788384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Compose(Compose(Compose(RankCutoff(BR(BM25), 1...</td>\n",
       "      <td>0.017559</td>\n",
       "      <td>0.064429</td>\n",
       "      <td>0.707140</td>\n",
       "      <td>411.478075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Compose(Compose(Compose(RankCutoff(BR(BM25), 1...</td>\n",
       "      <td>0.017929</td>\n",
       "      <td>0.065021</td>\n",
       "      <td>0.717578</td>\n",
       "      <td>3848.800651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Compose(Compose(Compose(RankCutoff(BR(BM25), 1...</td>\n",
       "      <td>0.017685</td>\n",
       "      <td>0.064586</td>\n",
       "      <td>0.712534</td>\n",
       "      <td>340.058003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Compose(Compose(Compose(RankCutoff(BR(BM25), 1...</td>\n",
       "      <td>0.017685</td>\n",
       "      <td>0.064586</td>\n",
       "      <td>0.712534</td>\n",
       "      <td>3094.988905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name       map      ndcg  \\\n",
       "0  Compose(Compose(Compose(RankCutoff(BR(BM25), 1...  0.017341  0.064571   \n",
       "1  Compose(Compose(Compose(RankCutoff(BR(BM25), 1...  0.017610  0.066213   \n",
       "2  Compose(Compose(Compose(RankCutoff(BR(BM25), 1...  0.017559  0.064429   \n",
       "3  Compose(Compose(Compose(RankCutoff(BR(BM25), 1...  0.017929  0.065021   \n",
       "4  Compose(Compose(Compose(RankCutoff(BR(BM25), 1...  0.017685  0.064586   \n",
       "5  Compose(Compose(Compose(RankCutoff(BR(BM25), 1...  0.017685  0.064586   \n",
       "\n",
       "   ndcg_cut_10          mrt  \n",
       "0     0.704892   379.139772  \n",
       "1     0.724416  3681.788384  \n",
       "2     0.707140   411.478075  \n",
       "3     0.717578  3848.800651  \n",
       "4     0.712534   340.058003  \n",
       "5     0.712534  3094.988905  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    [ca_pipe, ca_pipe_new, rf_pipe, rf_pipe_new, lmart_x_pipe, lmart_x_pipe_new],\n",
    "    valid_topics,\n",
    "    qrels, \n",
    "    eval_metrics=[\"map\", \"ndcg\", \"ndcg_cut_10\", \"mrt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:53:20.789 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
      "02:53:23.219 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
      "02:53:25.215 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:53:27.544 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 400 out of 400 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:53:29.667 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n",
      "02:53:31.910 [main] WARN org.terrier.querying.ApplyTermPipeline - The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "      <th>mrt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Compose(Compose(Compose(RankCutoff(BR(BM25), 1...</td>\n",
       "      <td>0.012273</td>\n",
       "      <td>0.049290</td>\n",
       "      <td>0.583235</td>\n",
       "      <td>275.312981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Compose(Compose(Compose(RankCutoff(BR(BM25), 1...</td>\n",
       "      <td>0.012245</td>\n",
       "      <td>0.049252</td>\n",
       "      <td>0.582693</td>\n",
       "      <td>159.541085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Compose(Compose(Compose(RankCutoff(BR(BM25), 1...</td>\n",
       "      <td>0.011271</td>\n",
       "      <td>0.045830</td>\n",
       "      <td>0.551404</td>\n",
       "      <td>135.109872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Compose(Compose(Compose(RankCutoff(BR(BM25), 1...</td>\n",
       "      <td>0.011362</td>\n",
       "      <td>0.046113</td>\n",
       "      <td>0.557297</td>\n",
       "      <td>156.735520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Compose(Compose(Compose(RankCutoff(BR(BM25), 1...</td>\n",
       "      <td>0.009926</td>\n",
       "      <td>0.042458</td>\n",
       "      <td>0.528034</td>\n",
       "      <td>129.474791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Compose(Compose(Compose(RankCutoff(BR(BM25), 1...</td>\n",
       "      <td>0.009926</td>\n",
       "      <td>0.042458</td>\n",
       "      <td>0.528034</td>\n",
       "      <td>148.184370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name       map      ndcg  \\\n",
       "0  Compose(Compose(Compose(RankCutoff(BR(BM25), 1...  0.012273  0.049290   \n",
       "1  Compose(Compose(Compose(RankCutoff(BR(BM25), 1...  0.012245  0.049252   \n",
       "2  Compose(Compose(Compose(RankCutoff(BR(BM25), 1...  0.011271  0.045830   \n",
       "3  Compose(Compose(Compose(RankCutoff(BR(BM25), 1...  0.011362  0.046113   \n",
       "4  Compose(Compose(Compose(RankCutoff(BR(BM25), 1...  0.009926  0.042458   \n",
       "5  Compose(Compose(Compose(RankCutoff(BR(BM25), 1...  0.009926  0.042458   \n",
       "\n",
       "   ndcg_cut_10         mrt  \n",
       "0     0.583235  275.312981  \n",
       "1     0.582693  159.541085  \n",
       "2     0.551404  135.109872  \n",
       "3     0.557297  156.735520  \n",
       "4     0.528034  129.474791  \n",
       "5     0.528034  148.184370  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    [ca_pipe, ca_pipe_new, rf_pipe, rf_pipe_new, lmart_x_pipe, lmart_x_pipe_new],\n",
    "    test_topics,\n",
    "    qrels, \n",
    "    eval_metrics=[\"map\", \"ndcg\", \"ndcg_cut_10\", \"mrt\"])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ECIR 2021 Tutorial Notebook - Part 2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "224e088c2ac64cc29b1d78a5e850ebe4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3cc8a8231dc44c768dffbc755dd0f2fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "cord19/trec-covid documents: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_587cc3f3700b4201b750e8fd3408e34d",
      "max": 192509,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ae5b4e71f7a74bb8aaa7c8bf1e985993",
      "value": 192509
     }
    },
    "562458b5bd6d4bb3a629932a2edc54d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3cc8a8231dc44c768dffbc755dd0f2fb",
       "IPY_MODEL_d998ea1d78fa458d94e3107bc2a514b5"
      ],
      "layout": "IPY_MODEL_224e088c2ac64cc29b1d78a5e850ebe4"
     }
    },
    "587cc3f3700b4201b750e8fd3408e34d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae5b4e71f7a74bb8aaa7c8bf1e985993": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c6b946af922e4b248a5bfecd99e11a8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d998ea1d78fa458d94e3107bc2a514b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb34c2ee16c241ea955bb088632f603d",
      "placeholder": "​",
      "style": "IPY_MODEL_c6b946af922e4b248a5bfecd99e11a8c",
      "value": " 192509/192509 [06:11&lt;00:00, 518.22it/s]"
     }
    },
    "eb34c2ee16c241ea955bb088632f603d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
